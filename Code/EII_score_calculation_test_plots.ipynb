{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baeb35bf-358a-4782-9f47-79b19a7065c2",
   "metadata": {},
   "source": [
    "# Ecosystem Integrity Index score (Dias et al., 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd6267-cf03-4bcc-84ca-9fd74147147f",
   "metadata": {},
   "source": [
    "This notebook is for computation of Ecosystem Integrity Index score (EII score) for a set of forested test lands called SEOME plots which are distributed around the globe, each having equal area (5 km2), but are covered with different quality of forest.\n",
    "\n",
    "In order to run the code, a BII map and a plantations map should be downloaded and added as personal Google Earth Engine (GEE) asset. \\\n",
    "The data for the BII map is available here: https://data.nhm.ac.uk/dataset/global-map-of-the-biodiversity-intactness-index-from-newbold-et-al-2016-science/resource/8531b4dc-bd44-4586-8216-47b3b8d60e85 \n",
    "\n",
    "The data for the plantations map is available here:\n",
    "https://www.arcgis.com/home/item.html?id=224e00192f6d408fa5147bbfc13b62dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34738349-d967-484e-a727-88b8c36cfac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap as gm\n",
    "\n",
    "# only needed for exporting data to csv\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a6c77c-1e91-4f02-a653-bd1d741f4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce27256-ac4e-4b63-9472-d7a551dfc240",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import datasets used\n",
    "First import the datasets used for computing EII.\\\n",
    "\\\n",
    "*NB*: in order to run the code, replace the path in bii and plantations variable with a path to the respective map.\n",
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f368b1fd-d396-449d-8822-0515b84b777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human footprint\n",
    "hf = ee.ImageCollection('CSP/HM/GlobalHumanModification')\n",
    "\n",
    "# hansen forest\n",
    "gfc = ee.Image('UMD/hansen/global_forest_change_2021_v1_9')\n",
    "\n",
    "# biodoversity intactness index\n",
    "\"\"\"\n",
    "NB this dataset is not freely available in Google Earth Engine but can be downloaded from this link:\n",
    "https://data.nhm.ac.uk/dataset/global-map-of-the-biodiversity-intactness-index-from-newbold-et-al-2016-science/resource/8531b4dc-bd44-4586-8216-47b3b8d60e85\n",
    "In order to run this code, replace the path to your own asset.\n",
    "\"\"\"\n",
    "bii = ee.Image(\"add/your/path\").rename('BII')\n",
    "\n",
    "# net primary production from Modis at 500m resolution\n",
    "npp = ee.ImageCollection(\"MODIS/006/MOD17A3HGF\").\\\n",
    "                  filter(ee.Filter.date('2015-01-01', '2020-01-01')).\\\n",
    "                  select('Npp');\n",
    "\n",
    "\n",
    "# this is forest total_connectivity(21) :\n",
    "connectivity_new = ee.Image('users/aduncan/osm_earth/total_connectivity_PRE2021_borealfixed')\n",
    "# this is forest total_connectivity_original() :\n",
    "connectivity_orig = ee.Image('users/aduncan/osm_earth/total_connectivity_original_borealfixed')\n",
    "\n",
    "# add plantations to exclude them \n",
    "\"\"\"\n",
    "NB this dataset is not freely available in Google Earth Engine but can be downloaded from this link:\n",
    "https://www.arcgis.com/home/item.html?id=224e00192f6d408fa5147bbfc13b62dd\n",
    "In order to run this code, replace the path to your own asset.\n",
    "\"\"\"\n",
    "plantations = ee.FeatureCollection('add/your/path')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a3d4e-94a7-4333-acc4-535245cfb3c0",
   "metadata": {},
   "source": [
    "Then import datasets for evaluating EII score results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b03d48-ed6e-4771-80c4-fcc5651515cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import biomes, ecoregions and realms\n",
    "biogeo = ee.FeatureCollection(\"RESOLVE/ECOREGIONS/2017\")\n",
    "\n",
    "# biomass dataset - only used for testing, not for eii calculation\n",
    "biomass = ee.Image(\"LARSE/GEDI/GEDI04_B_002\").select('MU')\n",
    "\n",
    "# digital elevation model - only used for testing, not for eii calculation\n",
    "# The Global Multi-resolution Terrain Elevation Data 2010 \n",
    "dem = ee.Image('USGS/GMTED2010').select('be75')\n",
    "\n",
    "# forest canopy height in 2020 - for testing average canopy of the plot\n",
    "canopyheight_20 = ee.Image('projects/glad/GLCLU2020/Forest_height_2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2905e-d62c-4cc4-bd47-13ac26398931",
   "metadata": {},
   "source": [
    "## Prepare the mask for the intact areas of the ecoregion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3057a5-918d-4353-8136-1e5bd5c5c2c0",
   "metadata": {},
   "source": [
    "The combination of small human footprint areas and hansen forest mask are used to later select global intact areas to find the 90th percentile value for each EBV. Plantations are removed from the intact areas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45197cb2-a8bc-4f79-bbf3-ea09704aa431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting pixels with high integrity by creating a binary mask. For now it includes all ecosystem (forest grassland etc)\n",
    "hf_mask = hf.select('gHM').first().lt(0.4);\n",
    "\n",
    "# create a mask for removing plantations\n",
    "plantations_ras = plantations.reduceToImage( reducer = ee.Reducer.first(), properties = ['OBJECTID'])\n",
    "\n",
    "# hansen intact forest\n",
    "treeCover = gfc.select(['treecover2000'])\n",
    "hansen_treecover = treeCover.gt(30)\n",
    "# add plantations as a band\n",
    "lossImage = gfc.select(['loss']).addBands(plantations_ras.select('first').gt(0))\n",
    "hansen_noloss_1 = lossImage.mask(hansen_treecover).eq(1); \n",
    "# filter out pixels with loss = 1\n",
    "hansen_noloss_plant = hansen_noloss_1.updateMask(hansen_noloss_1.select('loss').eq(0))\n",
    "# mask out plantations - this is the final forest mask\n",
    "hansen_noloss = hansen_noloss_plant.updateMask(hansen_noloss_plant.select('first').eq(0)).select('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f815df77-5b32-4b55-b114-96c1e68842dd",
   "metadata": {},
   "source": [
    "## Prepare the bii, npp and lfc layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662bb00-48d2-451a-8f01-b7cf456aa755",
   "metadata": {},
   "source": [
    "For each EBV create two layers with 1000 m resolution - one for high integrity forest where human footprint is less than 0.4 and the other for all areas which are inside forest ecosystem.\n",
    "\n",
    "First add biodiversity intactness index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eacfb61-2d14-4d3b-af77-45cd8154488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking bii by the high integrity pixels previously defined. BII layer is already at 1000 m resolution\n",
    "bii_high_integrity = bii.updateMask(hf_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b8f0a-5e7a-47a0-8be2-fb23ba71ecc8",
   "metadata": {},
   "source": [
    "Then, add net primary production and aggregate it to 1000 m resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb29b28f-d95d-4a6f-85f6-b6a216fcc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the collection with a using std reducer.\n",
    "mean_npp = npp.reduce(ee.Reducer.mean());\n",
    "mean_npp = mean_npp.rename('NPP')\n",
    "\n",
    "# aggregating NPP to the 1km res\n",
    "npp = mean_npp.\\\n",
    "    reproject(\n",
    "      crs = hf.first().projection(),\n",
    "      scale = 1000\n",
    "    ).\\\n",
    "    reduceResolution(\n",
    "      reducer = ee.Reducer.mean(),\n",
    "      maxPixels = 1024\n",
    "    )\n",
    "\n",
    "# masking npp by the high integrity pixels previously defined\n",
    "npp_high_integrity = npp.updateMask(hf_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d878496-7bdd-46e4-87ae-b83ce299bab0",
   "metadata": {},
   "source": [
    "Add loss of forest connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3535ebd9-3258-4ed8-898b-de215bd7207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed the variable names to avoid bugs, before all 3 were 'var lci'\n",
    "lci_0 = connectivity_new.divide(connectivity_orig.unmask(0.001).where(connectivity_orig.eq(0),0.001))\n",
    "lci_1 = lci_0.where(lci_0.gt(1),1)\n",
    "lci = lci_1.rename('LFC')\n",
    "\n",
    "# aggregate to 1km resolution and mask according to Hansen mask\n",
    "lfc = lci.\\\n",
    "    reduceResolution(\n",
    "      reducer = ee.Reducer.mean(),\n",
    "      maxPixels = 1024\n",
    "    ).\\\n",
    "    reproject(\n",
    "      crs = hf.first().projection(),\n",
    "      scale = 1000\n",
    "    )\n",
    "\n",
    "\n",
    "# mask lfc by the high integrity pixels previously defined\n",
    "lfc_high_integrity = lfc.updateMask(hf_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17343a77-898b-4809-a2b5-8685b1baf504",
   "metadata": {},
   "source": [
    "Add bands from high integrity bii, lfc and npp values to 30 m hansen intact forest. This creates the final layers from which the 90th percentile values for the 3 components are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "885ea754-bf9f-4205-9c5b-5ac348f1e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "hansen_bii = hansen_noloss.addBands(bii_high_integrity).updateMask(hansen_noloss.select('loss').eq(0)).select('BII')\n",
    "hansen_npp = hansen_noloss.addBands(npp_high_integrity).updateMask(hansen_noloss.select('loss').eq(0)).select('NPP')\n",
    "hansen_lfc = hansen_noloss.addBands(lfc_high_integrity).updateMask(hansen_noloss.select('loss').eq(0)).select('LFC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186d20f0-dc68-4527-b4ef-ba725864d334",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get the global 90th percentile values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c74d29-43f2-4953-aac3-0725121f5a51",
   "metadata": {},
   "source": [
    "This part is to show how the 90th percentile values of bii, npp and lfc from the global low human footprint plantation-free Hansen intact forest were calculated. These values were exported to Google Cloud Storage (GCS) and the next part of the code uses already values retrieved from the GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "382f7874-8851-4892-be81-94d628d0a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_task(image, aoi, asset_id):\n",
    "    ''' Compute the 90th percentile of an image over the given geometry\n",
    "    '''\n",
    "    percentile = image.reduceRegion(\n",
    "        reducer = ee.Reducer.percentile([90]),\n",
    "        geometry = aoi,\n",
    "        crs='EPSG:4326',\n",
    "        crsTransform=[0.00025, 0, -180, 0, -0.00025, 80],\n",
    "        maxPixels = 1e15\n",
    "    )\n",
    "    f = ee.Feature(aoi).set(percentile)\n",
    "    fc = ee.FeatureCollection(f)\n",
    "    \n",
    "    task = ee.batch.Export.table.toAsset(\n",
    "        collection=fc,\n",
    "        description=f'90th percentile',\n",
    "        assetId=asset_id\n",
    "    )\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57a2a846-629c-4a42-8988-3777c7e0f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the geometry covering the entire world\n",
    "aoi =  ee.Geometry.BBox(-180, -60, 180, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d371a-8361-4053-81a8-20262bfc0f23",
   "metadata": {},
   "source": [
    "Uncomment task.start() to submit the tasks. May take about 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7ff13da-b92f-404b-968b-653c1cc02413",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = percentile_task(hansen_bii, aoi, 'add/your/path')\n",
    "# task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94ec9735-604e-447c-a5a1-110b0c451192",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = percentile_task(hansen_npp, aoi, 'add/your/path')\n",
    "# task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad9be53a-d19f-477d-9260-32eeaf488624",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = percentile_task(hansen_lfc, aoi, 'add/your/path')\n",
    "# task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c99171-5ada-4df2-8684-0dd98d9c573c",
   "metadata": {},
   "source": [
    "Read back the values. Otherwise, they are expected to be the following and can be hard-coded:\\\n",
    "BII 90th percentile 1.0022686980875006\\\n",
    "NPP 90th percentile 12735.439316547474\\\n",
    "LFC 90th percentile 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "017dc1e9-e555-44cc-88da-9097c131630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BII 90th percentile 1.0022686980875006\n",
      "NPP 90th percentile 12735.439316547474\n",
      "LFC 90th percentile 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uncomment if retrieve values from feature saved to GCS\n",
    "fc_bii = 'enter/path/'\n",
    "fc_npp = 'enter/path/'\n",
    "fc_lfc = 'enter/path/'\n",
    "\n",
    "percentile_bii = ee.FeatureCollection(fc_bii).reduceColumns(ee.Reducer.first(), ['BII']).getInfo()['first']\n",
    "percentile_npp = ee.FeatureCollection(fc_npp).reduceColumns(ee.Reducer.first(), ['NPP']).getInfo()['first']\n",
    "percentile_lfc = ee.FeatureCollection(fc_lfc).reduceColumns(ee.Reducer.first(), ['LFC']).getInfo()['first']\n",
    "\"\"\"\n",
    "percentile_bii = 1.0022686980875006\n",
    "percentile_npp = 12735.439316547474\n",
    "percentile_lfc = 1\n",
    "\n",
    "print('BII 90th percentile', percentile_bii)\n",
    "print('NPP 90th percentile', percentile_npp)\n",
    "print('LFC 90th percentile', percentile_lfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7cebbb-e20c-42e3-bafd-ce6b74a607c9",
   "metadata": {},
   "source": [
    "Once the 90th percentile values have been retrieved, calculate the map of each EBV relative values against the respective 90th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e53f0f18-cd24-4234-ad93-5f8c529d1a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bii = bii.set({'90th_percentile': percentile_bii})\n",
    "npp = npp.set({'90th_percentile': percentile_npp})\n",
    "lfc = lfc.set({'90th_percentile': percentile_lfc})\n",
    "\n",
    "bii_relative = bii.where(bii.gt(percentile_bii), percentile_bii).divide(percentile_bii)\n",
    "npp_relative = npp.where(npp.gt(percentile_npp), percentile_npp).divide(percentile_npp)\n",
    "lfc_relative = lfc.where(lfc.gt(percentile_lfc), percentile_lfc).divide(percentile_lfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c5c71-23fb-44f9-ac31-6013438da254",
   "metadata": {},
   "source": [
    "## Show on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c19343b-baa3-4ada-be6a-43745c0ac4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b36b7b3d834a449b640bbd540d00ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = gm.Map(zoom=5)\n",
    "Map.setOptions('SATELLITE')\n",
    "\n",
    "Map.addLayer(bii,{min:0, max:1, 'palette': ['white','blue']}, 'bii', False)\n",
    "Map.addLayer(npp, {min:1000, max:20000, 'palette': ['white','red']}, 'npp', False)\n",
    "Map.addLayer(lfc, {min:0, max:1, 'palette': ['white','yellow']}, 'lfc', False)\n",
    "\n",
    "Map.addLayer(hansen_noloss, {'palette': 'green'}, 'Hansen', False)\n",
    "Map.addLayer(plantations_ras, {'palette': 'red'}, 'plantations mask', False)\n",
    "Map.addLayer(hansen_bii, {min:0, max:1, 'palette': ['white','blue']}, 'bii intact', False)\n",
    "Map.addLayer(hansen_npp, {min:1000, max:12700, 'palette': ['white','red']}, 'npp intact', False)\n",
    "Map.addLayer(hansen_lfc, {min:0, max:1, 'palette': ['white','yellow']}, 'lfc intact', False)\n",
    "\n",
    "Map.addLayer(bii_relative, {min:0, max:1, 'palette': ['white','blue']}, 'relative bii')\n",
    "Map.addLayer(npp_relative, {min:1000, max:12700, 'palette': ['white','red']}, 'relative npp')\n",
    "Map.addLayer(lfc_relative, {min:0, max:1, 'palette': ['white','yellow']}, 'relative lfc')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abc9cf-19a5-4e53-9916-9b61e2bc606a",
   "metadata": {},
   "source": [
    "## Function to stack bii, npp and lfc to one layer with three bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52e20b4a-de7c-4eaa-832d-ccf6f4c4cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendBands(image, previous):\n",
    "    return(ee.Image(previous).addBands(image))\n",
    "\n",
    "def stackCollection(collection):\n",
    "    first = ee.Image(collection.first()).select([])\n",
    "    return(ee.Image(collection.iterate(appendBands, first)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa96aae9-26f5-470a-9bf7-0a685c8caa29",
   "metadata": {},
   "source": [
    "## Calculate EII score for each plot and assess the sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870faeba-aa13-4180-b26e-0e641f9c48b6",
   "metadata": {},
   "source": [
    "Function to iterate over features, calculate the EII score for each feature and add it as its property. The function assumes round-shaped plots as it finds the center of the plot and creates new plots of 1, 2, 3 and 4 km2 around the center to test for the sensitivity of EII score to area. The sensitivity to the weights of the EBVs is tested by calculating the EII score using different weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be9691ae-878d-4dcc-944e-6983945fa840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eii_sensitivity_seome(feature): \n",
    "    \n",
    "    # 1. PREPARE DATA ON ECOREGION\n",
    "    # This is for understanding EII score variabilty within and between ecoregions\n",
    "    \n",
    "    # find the biome where the plot is in\n",
    "    biome_name = ee.String(ee.FeatureCollection(biogeo.filterBounds(feature.geometry())).first().get('BIOME_NAME'))\n",
    "    # find the realm in which the plot is in\n",
    "    realm = ee.String(ee.FeatureCollection(biogeo.filterBounds(feature.geometry())).first().get('REALM'))\n",
    "    # find the ecoregion in which the plot is in\n",
    "    ecoregion_nr = ee.Number(ee.FeatureCollection(biogeo.filterBounds(feature.geometry())).first().get('ECO_ID'))\n",
    "    ecoregion_name = ee.String(ee.FeatureCollection(biogeo.filterBounds(feature.geometry())).first().get('ECO_NAME'))\n",
    "    biome_num = ee.Number(ee.FeatureCollection(biogeo.filterBounds(feature.geometry())).first().get('BIOME_NUM'))\n",
    "    \n",
    "\n",
    "    # 2. PREPARE EII IMAGE \n",
    "    \n",
    "    # if any of the mean components is missing, they should for now be 0 - this is to avoid crashing\n",
    "    mean_bii = ee.Image(ee.Algorithms.If(bii_relative,  bii_relative, ee.Image.constant(0)))\n",
    "    mean_NPP = ee.Image(ee.Algorithms.If(npp_relative, npp_relative,  ee.Image.constant(0)))\n",
    "    mean_lfc = ee.Image(ee.Algorithms.If(lfc_relative, lfc_relative,  ee.Image.constant(0)))\n",
    "    \n",
    "    # add all 3 images together\n",
    "    eiiCollection = ee.ImageCollection.fromImages(\n",
    "        [mean_bii, mean_NPP, mean_lfc]);\n",
    "    \n",
    "    # create masks for areas where either of the 3 components is missing \n",
    "    noDataMask_bii = (ee.Image(stackCollection(eiiCollection).select('BII')).unmask(-99))\n",
    "    noDataMask_npp = (ee.Image(stackCollection(eiiCollection).select('NPP')).unmask(-99))\n",
    "    noDataMask_lfc = (ee.Image(stackCollection(eiiCollection).select('LFC')).unmask(-99))\n",
    "\n",
    "    \n",
    "    \n",
    "    # 3. CALCULATE THE EII SCORE FOR THE ORIGINAL AREA OF THE PLOT (5KM2)\n",
    "    \n",
    "    # use function defined above to take the mean of the 3 components\n",
    "    # then use the 3 masks to mask out any pixels that miss any of the 3 values\n",
    "    \n",
    "    eii_average = stackCollection(eiiCollection).reduce('mean').updateMask(noDataMask_bii).\\\n",
    "    updateMask(noDataMask_npp).updateMask(noDataMask_lfc)\n",
    "\n",
    "    # find the mean of eii of the plot - for analysis\n",
    "    eii_plot_mean = ee.Number((eii_average.reduceRegion(\n",
    "    reducer = ee.Reducer.mean(),\n",
    "    geometry = feature.geometry(),\n",
    "    scale = 1000\n",
    "  )).get('mean'));\n",
    "    \n",
    "    # find the eii sum of the plot - the EII score\n",
    "    eii_plot_sum = ee.Number((eii_average.reduceRegion(\n",
    "    reducer = ee.Reducer.sum(),\n",
    "    geometry = feature.geometry(),\n",
    "    scale = 1000\n",
    "  )).get('mean'));\n",
    "    \n",
    "    \n",
    "\n",
    "    # 4. ADD THE MEAN BIOMASS, MEAN CANOPY HEIGHT AND ELEVATION OF THE PLOT FOR ANALYSIS\n",
    "    \n",
    "    biomass_plot = ee.Number((biomass.updateMask(noDataMask_bii).\\\n",
    "    updateMask(noDataMask_npp).updateMask(noDataMask_lfc).reduceRegion(\n",
    "    reducer = ee.Reducer.mean(),\n",
    "    geometry = feature.geometry(),\n",
    "    scale = 1000\n",
    "  )).get('MU'));\n",
    "    \n",
    "    # only to test if plots elevation introduces noise\n",
    "    elevation = dem.reduceRegion(\n",
    "        reducer = ee.Reducer.mean(),\n",
    "        geometry = feature.geometry(),\n",
    "        scale = 90\n",
    "    )\n",
    "    \n",
    "    # find the canopy height of the plot\n",
    "    mean_canopy = ee.Number(canopyheight_20.updateMask(noDataMask_bii).\\\n",
    "    updateMask(noDataMask_npp).updateMask(noDataMask_lfc).reduceRegion(\n",
    "        reducer = ee.Reducer.mean(),\n",
    "        geometry = feature.geometry(),\n",
    "        scale = 30).get('b1')\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 5. SENSITIVITY ANALYSIS TO CHANGE THE WEIGHTS OF THE 3 COMPONENTS\n",
    "    \n",
    "    # first if one of the components weighs 50% and the other two 25%\n",
    "    bii50 = ee.Number(ee.Image(mean_bii.multiply(ee.Number(0.5)).\\\n",
    "                               add((mean_NPP).multiply(ee.Number(0.25))).\\\n",
    "                               add(mean_lfc.multiply(ee.Number(0.25)))).\\\n",
    "                      # mask out the pixels that are missing either of the 3 values\n",
    "                      updateMask(noDataMask_bii).updateMask(noDataMask_npp).updateMask(noDataMask_lfc).\\\n",
    "    reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = feature.geometry(),\n",
    "        scale = 1000\n",
    "    ).get('BII'))\n",
    "    \n",
    "    # if npp has 50% weightand the other two 25%\n",
    "    npp50 = ee.Number(ee.Image(mean_bii.multiply(ee.Number(0.25)).\\\n",
    "                               add((mean_NPP).multiply(ee.Number(0.5))).\\\n",
    "                               add(mean_lfc.multiply(ee.Number(0.25)))).\\\n",
    "                      updateMask(noDataMask_bii).updateMask(noDataMask_npp).updateMask(noDataMask_lfc).\\\n",
    "    reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = feature.geometry(),\n",
    "        scale = 1000\n",
    "    ).get('BII')) # get bii as the npp and lfc values were added to the bii value\n",
    "    \n",
    "    # if lfc has 50% weight and the other two 25%\n",
    "    lfc50 = ee.Number(ee.Image(mean_bii.multiply(ee.Number(0.25)).\\\n",
    "                               add((mean_NPP).multiply(ee.Number(0.25))).\\\n",
    "                               add(mean_lfc.multiply(ee.Number(0.5)))).\\\n",
    "                      updateMask(noDataMask_bii).updateMask(noDataMask_npp).updateMask(noDataMask_lfc).\\\n",
    "    reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = feature.geometry(),\n",
    "        scale = 1000\n",
    "    ).get('BII'))\n",
    "    \n",
    "    # then, if one of the component is 0 and the other 2 is 50%\n",
    "    bii0 = ee.Number(ee.Image(mean_bii.multiply(ee.Number(0.0)).\\\n",
    "                              add((mean_NPP).multiply(ee.Number(0.5))).\\\n",
    "                              add(mean_lfc.multiply(ee.Number(0.5)))).\\\n",
    "                     updateMask(noDataMask_bii).updateMask(noDataMask_npp).updateMask(noDataMask_lfc).\\\n",
    "    reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = feature.geometry(),\n",
    "        scale = 1000\n",
    "    ).get('BII'))\n",
    "    \n",
    "    # if npp is 0 and the other 2 is 50%\n",
    "    npp0 = ee.Number(ee.Image(mean_bii.multiply(ee.Number(0.5)).\\\n",
    "                              add((mean_NPP).multiply(ee.Number(0.0))).\\\n",
    "                              add(mean_lfc.multiply(ee.Number(0.5)))).\\\n",
    "                     updateMask(noDataMask_bii).updateMask(noDataMask_npp).updateMask(noDataMask_lfc).\\\n",
    "    reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = feature.geometry(),\n",
    "        scale = 1000\n",
    "    ).get('BII'))\n",
    "    \n",
    "    # if lfc is 0 and the other 2 is 50%\n",
    "    lfc0 = ee.Number(ee.Image(mean_bii.multiply(ee.Number(0.5)).\\\n",
    "                              add((mean_NPP).multiply(ee.Number(0.5))).\\\n",
    "                              add(mean_lfc.multiply(ee.Number(0.0)))).\\\n",
    "                     updateMask(noDataMask_bii).updateMask(noDataMask_npp).updateMask(noDataMask_lfc).\\\n",
    "    reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = feature.geometry(),\n",
    "        scale = 1000\n",
    "    ).get('BII'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 6. SENSITIVITY ANALYSIS TO THE CHANGING AREA OF THE PLOT\n",
    "    \n",
    "    #get the center point of the plot, then create buffers around the center\n",
    "    center = feature.centroid();\n",
    "    \n",
    "    # then create 1, 2, 3, 4 km2 buffers around the plot's center\n",
    "    buf1 = center.buffer(ee.Number(1e6).sqrt().divide(1.7725267552), 1)\n",
    "    \n",
    "    #calculate the average eii in the respective buffer\n",
    "    eii1 = ee.Number((eii_average.reduceRegion(\n",
    "    reducer = ee.Reducer.sum(),\n",
    "    geometry = buf1.geometry(),\n",
    "    scale = 1000\n",
    "  )).get('mean'));\n",
    "    \n",
    "    buf2 = center.buffer(ee.Number(2e6).sqrt().divide(1.7725267552), 1)\n",
    "    \n",
    "    eii2 = ee.Number((eii_average.reduceRegion(\n",
    "    reducer = ee.Reducer.sum(),\n",
    "    geometry = buf2.geometry(),\n",
    "    scale = 1000\n",
    "  )).get('mean'));\n",
    "    \n",
    "    buf3 = center.buffer(ee.Number(3e6).sqrt().divide(1.7725267552), 1)\n",
    "    \n",
    "    eii3 = ee.Number((eii_average.reduceRegion(\n",
    "    reducer = ee.Reducer.sum(),\n",
    "    geometry = buf3.geometry(),\n",
    "    scale = 1000\n",
    "  )).get('mean'));\n",
    "    \n",
    "    buf4 = center.buffer(ee.Number(4e6).sqrt().divide(1.7725267552), 1)\n",
    "    \n",
    "    eii4 = ee.Number((eii_average.reduceRegion(\n",
    "    reducer = ee.Reducer.sum(),\n",
    "    geometry = buf4.geometry(),\n",
    "    scale = 1000\n",
    "  )).get('mean'));\n",
    "    \n",
    "\n",
    "    return(feature.set({'realm': realm, 'biome': biome_name, 'ecoregion': ecoregion_name,\\\n",
    "                        'ecoregion_nr': ecoregion_nr, 'mean_elevation': ee.Number(elevation.get('be75')),\\\n",
    "                        'eii_sum': eii_plot_sum, 'eii_mean': eii_plot_mean, 'biomass': biomass_plot, 'mean_canopy2020': mean_canopy,\\\n",
    "                        'senW_bii50': bii50,'senW_npp50': npp50, 'senW_lfc50': lfc50, 'senW_bii0': bii0, 'senW_npp0': npp0, 'senW_lfc0': lfc0,\\\n",
    "                        'senA_1km2': eii1, 'senA_2km2': eii2, 'senA_3km2': eii3, 'senA_4km2': eii4}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb6e77-c1ef-4e5a-aada-fea5c1d86acf",
   "metadata": {},
   "source": [
    "## Calculate EII score and its sensitivity for a set of test plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad17b9-9633-4465-abb6-443f2d429ca8",
   "metadata": {},
   "source": [
    "The values presented in the article are calculated using a set of test plots hereafter called *Seome plots*.\n",
    "\n",
    "Seome plots are categorised to the following regions: North America (NAmerica), South America (SAmerica), East Asia (EastAsia), South Asia (SAsia), North Asia (NAsia), Australia, Europe and Africa.\n",
    "\n",
    "There are Seome plots which are located on an island, intersect with plantations or are located above the elevation threshold set in the methods (1000 m above the sea level). These plots were removed in post-processing, the code does not filter them out.\n",
    "\n",
    "The plots are categorised to Top and Down category in which Top category plots were assessed to contain high quality of forest and expected to have higher EII score.\n",
    "Some Seome plots have Down category marked as Down or DOWN.\n",
    "\n",
    "The code may not be able to run all the plots together, it is wise to filter and process the plots region by region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8e96f92-ea82-44df-b67c-6030a459aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out middle category\n",
    "seome_all = ee.FeatureCollection('projects/ee-katrinmschn/assets/seome_plots_public')\n",
    "# Choose the region which plots to analyse - this is also used for the exported csv file\n",
    "#region = 'Europe'\n",
    "#seome = seome_all.filter(ee.Filter.eq('Region', region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b80d33e9-872d-4d2c-bb96-50a4903c418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of Seome plots to analyse:  333\n"
     ]
    }
   ],
   "source": [
    "print('Nr of Seome plots to analyse: ', seome_all.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04509127-ee94-4e99-888d-253cdae7e529",
   "metadata": {},
   "source": [
    "Iterate over all Seome plots and show the output in geopandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a93e4c48-7e7f-496d-a618-55e87f53c428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category_n</th>\n",
       "      <th>Region</th>\n",
       "      <th>biomass</th>\n",
       "      <th>biome</th>\n",
       "      <th>ecoregion</th>\n",
       "      <th>ecoregion_nr</th>\n",
       "      <th>eii_mean</th>\n",
       "      <th>eii_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>senA_1km2</th>\n",
       "      <th>senA_2km2</th>\n",
       "      <th>senA_3km2</th>\n",
       "      <th>senA_4km2</th>\n",
       "      <th>senW_bii0</th>\n",
       "      <th>senW_bii50</th>\n",
       "      <th>senW_lfc0</th>\n",
       "      <th>senW_lfc50</th>\n",
       "      <th>senW_npp0</th>\n",
       "      <th>senW_npp50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((20.86171 -1.23526, 20.86173 -1.23590...</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>Africa</td>\n",
       "      <td>118.155263</td>\n",
       "      <td>Tropical &amp; Subtropical Moist Broadleaf Forests</td>\n",
       "      <td>Central Congolian lowland forests</td>\n",
       "      <td>3</td>\n",
       "      <td>0.937740</td>\n",
       "      <td>4.703410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919762</td>\n",
       "      <td>1.850476</td>\n",
       "      <td>2.828746</td>\n",
       "      <td>3.758860</td>\n",
       "      <td>4.735044</td>\n",
       "      <td>4.688436</td>\n",
       "      <td>4.548236</td>\n",
       "      <td>4.781840</td>\n",
       "      <td>4.828636</td>\n",
       "      <td>4.641640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((20.35370 -2.04621, 20.35372 -2.04684...</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>Africa</td>\n",
       "      <td>256.418424</td>\n",
       "      <td>Tropical &amp; Subtropical Moist Broadleaf Forests</td>\n",
       "      <td>Central Congolian lowland forests</td>\n",
       "      <td>3</td>\n",
       "      <td>0.945421</td>\n",
       "      <td>4.734519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945772</td>\n",
       "      <td>1.898373</td>\n",
       "      <td>2.843644</td>\n",
       "      <td>3.792780</td>\n",
       "      <td>4.842047</td>\n",
       "      <td>4.685457</td>\n",
       "      <td>4.602575</td>\n",
       "      <td>4.805192</td>\n",
       "      <td>4.768338</td>\n",
       "      <td>4.722311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((24.66684 -1.64592, 24.66686 -1.64655...</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>Africa</td>\n",
       "      <td>222.077469</td>\n",
       "      <td>Tropical &amp; Subtropical Moist Broadleaf Forests</td>\n",
       "      <td>Central Congolian lowland forests</td>\n",
       "      <td>3</td>\n",
       "      <td>0.969330</td>\n",
       "      <td>4.854250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972873</td>\n",
       "      <td>1.945883</td>\n",
       "      <td>2.915468</td>\n",
       "      <td>3.884880</td>\n",
       "      <td>4.785279</td>\n",
       "      <td>4.888736</td>\n",
       "      <td>4.777454</td>\n",
       "      <td>4.892649</td>\n",
       "      <td>5.000018</td>\n",
       "      <td>4.781367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((26.13901 -0.08608, 26.13904 -0.08672...</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>Africa</td>\n",
       "      <td>214.501557</td>\n",
       "      <td>Tropical &amp; Subtropical Moist Broadleaf Forests</td>\n",
       "      <td>Northeast Congolian lowland forests</td>\n",
       "      <td>24</td>\n",
       "      <td>0.918922</td>\n",
       "      <td>4.479296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921767</td>\n",
       "      <td>1.743121</td>\n",
       "      <td>2.629815</td>\n",
       "      <td>3.563611</td>\n",
       "      <td>4.423082</td>\n",
       "      <td>4.507018</td>\n",
       "      <td>4.575428</td>\n",
       "      <td>4.430845</td>\n",
       "      <td>4.438608</td>\n",
       "      <td>4.499255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((16.75669 -0.19595, 16.75671 -0.19658...</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tropical &amp; Subtropical Moist Broadleaf Forests</td>\n",
       "      <td>Western Congolian swamp forests</td>\n",
       "      <td>29</td>\n",
       "      <td>0.924396</td>\n",
       "      <td>4.636481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934918</td>\n",
       "      <td>1.862241</td>\n",
       "      <td>2.750256</td>\n",
       "      <td>3.686094</td>\n",
       "      <td>4.697793</td>\n",
       "      <td>4.599183</td>\n",
       "      <td>4.440236</td>\n",
       "      <td>4.727961</td>\n",
       "      <td>4.758129</td>\n",
       "      <td>4.569015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry Category Category_n  \\\n",
       "0  POLYGON ((20.86171 -1.23526, 20.86173 -1.23590...        1        Top   \n",
       "1  POLYGON ((20.35370 -2.04621, 20.35372 -2.04684...        1        Top   \n",
       "2  POLYGON ((24.66684 -1.64592, 24.66686 -1.64655...        1        Top   \n",
       "3  POLYGON ((26.13901 -0.08608, 26.13904 -0.08672...        1        Top   \n",
       "4  POLYGON ((16.75669 -0.19595, 16.75671 -0.19658...        1        Top   \n",
       "\n",
       "   Region     biomass                                           biome  \\\n",
       "0  Africa  118.155263  Tropical & Subtropical Moist Broadleaf Forests   \n",
       "1  Africa  256.418424  Tropical & Subtropical Moist Broadleaf Forests   \n",
       "2  Africa  222.077469  Tropical & Subtropical Moist Broadleaf Forests   \n",
       "3  Africa  214.501557  Tropical & Subtropical Moist Broadleaf Forests   \n",
       "4  Africa         NaN  Tropical & Subtropical Moist Broadleaf Forests   \n",
       "\n",
       "                             ecoregion  ecoregion_nr  eii_mean   eii_sum  ...  \\\n",
       "0    Central Congolian lowland forests             3  0.937740  4.703410  ...   \n",
       "1    Central Congolian lowland forests             3  0.945421  4.734519  ...   \n",
       "2    Central Congolian lowland forests             3  0.969330  4.854250  ...   \n",
       "3  Northeast Congolian lowland forests            24  0.918922  4.479296  ...   \n",
       "4      Western Congolian swamp forests            29  0.924396  4.636481  ...   \n",
       "\n",
       "   senA_1km2  senA_2km2 senA_3km2 senA_4km2 senW_bii0 senW_bii50  senW_lfc0  \\\n",
       "0   0.919762   1.850476  2.828746  3.758860  4.735044   4.688436   4.548236   \n",
       "1   0.945772   1.898373  2.843644  3.792780  4.842047   4.685457   4.602575   \n",
       "2   0.972873   1.945883  2.915468  3.884880  4.785279   4.888736   4.777454   \n",
       "3   0.921767   1.743121  2.629815  3.563611  4.423082   4.507018   4.575428   \n",
       "4   0.934918   1.862241  2.750256  3.686094  4.697793   4.599183   4.440236   \n",
       "\n",
       "   senW_lfc50  senW_npp0  senW_npp50  \n",
       "0    4.781840   4.828636    4.641640  \n",
       "1    4.805192   4.768338    4.722311  \n",
       "2    4.892649   5.000018    4.781367  \n",
       "3    4.430845   4.438608    4.499255  \n",
       "4    4.727961   4.758129    4.569015  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seome_eii = seome_all.map(eii_sensitivity_seome)\n",
    "gdf = gm.ee_to_geopandas(seome_eii)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc85c20-4222-44ad-9301-485c730575d0",
   "metadata": {},
   "source": [
    "Uncomment to export as file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5674631f-762f-4bac-be93-067489a20b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to export the geodataframe to shapefile  - allows to check in QGIS and export as CSV\n",
    "#gdf.to_file('eii_sensitivity_'+ region + '.shp)\n",
    "\n",
    "# export the geodataframe to csv\n",
    "filename =  'exported_eii/eii_score.csv'\n",
    "#pd.DataFrame(gdf.assign(geometry=gdf[\"geometry\"].apply(lambda p: p.wkt))).to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m86"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
